{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad0affa",
   "metadata": {},
   "source": [
    "<div class=\"table-of-contents\" style=\"background-color:#000000; padding: 20px; margin: 10px; font-size: 110%; border-radius: 25px; box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\">\n",
    "  <h1 style=\"color:white;\">TOC</h1>\n",
    "  <ol>\n",
    "    <li><a href=\"#1\" style=\"color: white;\">1. Overview</a></li>\n",
    "      <li><a href=\"#2\" style=\"color: white;\">2. Imports</a></li>\n",
    "    <li><a href=\"#3\" style=\"color: white;\">3. Data Analysis</a></li>\n",
    "    <li><a href=\"#4\" style=\"color: white;\">4. Model Implementation From Scratch</a></li>\n",
    "    <li><a href=\"#5\" style=\"color: white;\">5. SKlearn Implementation</a></li> \n",
    "    <li><a href=\"#6\" style=\"color: white;\">6. Evaluation</a></li>\n",
    "    <li><a href=\"#7\" style=\"color: white;\">7. Thank You</a></li>  \n",
    "  </ol>\n",
    "</div>\n",
    "\n",
    "<a id=\"1\"></a>\n",
    "<h1 style='background:#000000;border:0; color:black;\n",
    "    box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\n",
    "    transform: rotateX(10deg);\n",
    "    '><center style='color: white;'>Overview</center></h1>\n",
    "\n",
    "# Overview\n",
    "  \n",
    "**In this notebook, we will be implementing the K-Nearest Neighbors (KNN) algorithm from scratch. KNN is a supervised machine learning algorithm that can be used for both classification and regression tasks. It is a non-parametric method that makes predictions based on the similarity of new data points to the labeled data points in the training set.**\n",
    "\n",
    "**The main objective of this notebook is to understand the inner workings of the KNN algorithm and how it can be implemented without relying on existing libraries or frameworks. By building the algorithm from scratch, we will gain a deeper understanding of its underlying principles and mechanics.**\n",
    "    \n",
    "**Let's get started !**    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41792f0f",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<h1 style='background:#000000;border:0; color:black;\n",
    "    box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\n",
    "    transform: rotateX(10deg);\n",
    "    '><center style='color: white;'>Imports</center></h1>\n",
    "\n",
    "# Imports\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3671d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f3861",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<h1 style='background:#000000;border:0; color:black;\n",
    "    box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\n",
    "    transform: rotateX(10deg);\n",
    "    '><center style='color: white;'>Data Analysis</center></h1>\n",
    "\n",
    "# Data Analysis\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f841263",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"../input/iris/Iris.csv\") #Load Data\n",
    "iris.drop('Id',inplace=True,axis=1) #Drop Id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b9dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head().style.background_gradient(sns.color_palette(\"YlOrBr\", as_cmap=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b64ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.iloc[:,:-1] #Set our training data\n",
    "\n",
    "y = iris.iloc[:,-1] #Set training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(iris, 'Species',color_discrete_sequence=['#ffffd4 ','#fe9929 ','#993404 '],title='Data Distribution',template='plotly_dark')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b0e1f1",
   "metadata": {},
   "source": [
    "## From this plot we conclude that:\n",
    "\n",
    "**The Data is perfectly balanced**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5323ee7",
   "metadata": {},
   "source": [
    "## Sepal-Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de4b2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(data_frame=iris, x='Species',y='SepalLengthCm',color='Species',color_discrete_sequence=['#ffffd4 ','#fe9929 ','#993404 '], template='plotly_dark',orientation='v')\n",
    " \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7db964",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(data_frame=iris, x='SepalLengthCm',color='Species',color_discrete_sequence=['#ffffd4 ','#fe9929 ','#993404 '], template='plotly_dark',nbins=50)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c530c8b3",
   "metadata": {},
   "source": [
    "### From these plots we conclude that: \n",
    "\n",
    "* **Setosa has much smaller SepalLength than the other 2 classes**\n",
    "\n",
    "* **Virginca has the highest SepalLength, however It seems hard to distingush between Virginca and Versicolor using SepalLength as the difference is less clear**\n",
    "\n",
    "* **We can see that Virginica contains an outlier**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0121f3a4",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354b98a8",
   "metadata": {},
   "source": [
    "## SepalWidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89859d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(data_frame=iris, x='Species',y='SepalWidthCm',color='Species',color_discrete_sequence=['#ffffd4 ','#fe9929 ','#993404 '], template='plotly_dark',orientation='v')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79552cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(data_frame=iris, x='SepalWidthCm',color='Species',color_discrete_sequence=['#ffffd4 ','#fe9929 ','#993404 '], template='plotly_dark',nbins=30)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a84fae",
   "metadata": {},
   "source": [
    "### From these plots we conclude that: \n",
    "\n",
    "* **Setosa has  larger SepalWidth than the other 2 classes**\n",
    "\n",
    "* **Versicolo has smaller SepalWidth than the other 2 classes**\n",
    "\n",
    "* **Overall all classes seem to have relatively close value of sepalwidth which indicate that is might not be a very useful feature**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16656d9c",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cac04f",
   "metadata": {},
   "source": [
    "## Petal-Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32584711",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(data_frame=iris, x='Species',y='PetalLengthCm',color='Species',color_discrete_sequence=['#ffffd4 ','#fe9929 ','#993404 '], template='plotly_dark',orientation='v')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdc633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(data_frame=iris, x='PetalLengthCm',color='Species',color_discrete_sequence=['#ffffd4 ','#fe9929 ','#993404 '], template='plotly_dark',nbins=30)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd417b",
   "metadata": {},
   "source": [
    "### From these plots we conclude that: \n",
    "\n",
    "* **Setosa has much smaller PetaLength than the other 2 classes**\n",
    "\n",
    "* **This difference is less clear between Virginica and Versicolor**\n",
    "\n",
    "* **Overall this seems like an  PetaLength interesting feature**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c017bc1e",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79706b93",
   "metadata": {},
   "source": [
    "## Petal-Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d48b622",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(data_frame=iris, x='Species',y='PetalWidthCm',color='Species',color_discrete_sequence=['#ffffd4 ','#fe9929 ','#993404 '], template='plotly_dark',orientation='v')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da0fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(data_frame=iris, x='PetalWidthCm',color='Species',color_discrete_sequence=['#ffffd4 ','#fe9929 ','#993404 '], template='plotly_dark',nbins=30)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf6c75",
   "metadata": {},
   "source": [
    "### From these plots we conclude that: \n",
    "\n",
    "* **Setosa has much smaller PetalWidth than the other 2 classes**\n",
    "\n",
    "* **This difference is less clear between Virginica and Versicolor**\n",
    "\n",
    "* **Overall this seems like an  PetalWidth interesting feature**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584066a8",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c04d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(data_frame=iris, x='SepalLengthCm',y='SepalWidthCm'\n",
    "           ,color='Species',size='PetalLengthCm', color_discrete_sequence=['#ffffd4 ','#fe9929 ','#993404 '], template='plotly_dark',)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027a27cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(data_frame=iris, x='PetalLengthCm',y='PetalWidthCm'\n",
    "           ,color='Species',size='SepalLengthCm', color_discrete_sequence=['#ffffd4 ','#fe9929 ','#993404 '], template='plotly_dark',)\n",
    " \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd1e9c4",
   "metadata": {},
   "source": [
    "### From this plots we conclude that: \n",
    "\n",
    "* **the Setosa species generally have shorter sepal length and width compared to the other two species**\n",
    "\n",
    "* **the Setosa species generally have shorter petal length and width compared to the other two species**\n",
    "\n",
    "* **Versicolor and Virginica species overlap in terms of sepal length and width, making it more difficult to distinguish between them based on these two features alone**\n",
    "\n",
    "* **There is a positive correlation between sepal length and petal length, as well as between sepal width and petal length..**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a0a17a",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<h1 style='background:#000000;border:0; color:black;\n",
    "    box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\n",
    "    transform: rotateX(10deg);\n",
    "    '><center style='color: white;'>Model Implementation From Scratch</center></h1>\n",
    "\n",
    "# Model Implementation From Scratch\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e30182",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## How the algorithm works\n",
    "\n",
    "**We calculate the euclidean distance between a new sample and all points**\n",
    "\n",
    "**We determine the label of the sample based on the majority vote**\n",
    "\n",
    "## Key Points:\n",
    "\n",
    "### Euclidean Distance\n",
    "**Euclidean distance is defined as the distance between two points**\n",
    "\n",
    "**Where it's represented by this equation :\n",
    "$$\\sqrt{\\sum\\limits_{i = 0}^{m-1} (x - y)^2}$$**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    \"\"\"\n",
    "    K-Nearest Neighbors (KNN) classification algorithm\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_neighbors : int, optional (default=5)\n",
    "        Number of neighbors to use in the majority vote.\n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "    fit(X_train, y_train):\n",
    "        Stores the values of X_train and y_train.\n",
    "\n",
    "    predict(X):\n",
    "        Predicts the class labels for each example in X.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_neighbors=5):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        \n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Calculate the Euclidean distance between two data points.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        x1 : numpy.ndarray, shape (n_features,)\n",
    "            A data point in the dataset.\n",
    "        \n",
    "        x2 : numpy.ndarray, shape (n_features,)\n",
    "            A data point in the dataset.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        distance : float\n",
    "            The Euclidean distance between x1 and x2.\n",
    "        \"\"\"\n",
    "        return np.linalg.norm(x1 - x2)\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Stores the values of X_train and y_train.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X_train : numpy.ndarray, shape (n_samples, n_features)\n",
    "            The training dataset.\n",
    "\n",
    "        y_train : numpy.ndarray, shape (n_samples,)\n",
    "            The target labels.\n",
    "        \"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts the class labels for each example in X.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy.ndarray, shape (n_samples, n_features)\n",
    "            The test dataset.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        predictions : numpy.ndarray, shape (n_samples,)\n",
    "            The predicted class labels for each example in X.\n",
    "        \"\"\"\n",
    "        # Create empty array to store the predictions\n",
    "        predictions = []\n",
    "        # Loop over X examples\n",
    "        for x in X:\n",
    "            # Get prediction using the prediction helper function\n",
    "            prediction = self._predict(x)\n",
    "            # Append the prediction to the predictions list\n",
    "            predictions.append(prediction)\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        \"\"\"\n",
    "        Predicts the class label for a single example.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        x : numpy.ndarray, shape (n_features,)\n",
    "            A data point in the test dataset.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        most_occuring_value : int\n",
    "            The predicted class label for x.\n",
    "        \"\"\"\n",
    "        # Create empty array to store distances\n",
    "        distances = []\n",
    "        # Loop over all training examples and compute the distance between x and all the training examples \n",
    "        for x_train in self.X_train:\n",
    "            distance = self.euclidean_distance(x, x_train)\n",
    "            distances.append(distance)\n",
    "        distances = np.array(distances)\n",
    "        \n",
    "        # Sort by ascendingly distance and return indices of the given n neighbours\n",
    "        n_neighbors_idxs = np.argsort(distances)[: self.n_neighbors]\n",
    "        \n",
    "        # Get labels of n-neighbour indexes\n",
    "        labels = self.y_train[n_neighbors_idxs]                  \n",
    "        labels = list(labels)\n",
    "        # Get the most frequent class in the array\n",
    "        most_occuring_value = max(labels, key=labels.count)\n",
    "        return most_occuring_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039f9622",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "<h1 style='background:#000000;border:0; color:black;\n",
    "    box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\n",
    "    transform: rotateX(10deg);\n",
    "    '><center style='color: white;'>Evaluation</center></h1>\n",
    "\n",
    "# Evaluation\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d477f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, random_state=42, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Splits the data into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "        X (numpy.ndarray): Features array of shape (n_samples, n_features).\n",
    "        y (numpy.ndarray): Target array of shape (n_samples,).\n",
    "        random_state (int): Seed for the random number generator. Default is 42.\n",
    "        test_size (float): Proportion of samples to include in the test set. Default is 0.2.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[numpy.ndarray]: A tuple containing X_train, X_test, y_train, y_test.\n",
    "    \"\"\"\n",
    "    # Get number of samples\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    # Set the seed for the random number generator\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Shuffle the indices\n",
    "    shuffled_indices = np.random.permutation(np.arange(n_samples))\n",
    "\n",
    "    # Determine the size of the test set\n",
    "    test_size = int(n_samples * test_size)\n",
    "\n",
    "    # Split the indices into test and train\n",
    "    test_indices = shuffled_indices[:test_size]\n",
    "    train_indices = shuffled_indices[test_size:]\n",
    "\n",
    "    # Split the features and target arrays into test and train\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c451e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size = 0.2, random_state=42) #split the  data into traing and validating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed4aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNN(7)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d171263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of a classification model.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (numpy array): A numpy array of true labels for each data point.\n",
    "    y_pred (numpy array): A numpy array of predicted labels for each data point.\n",
    "\n",
    "    Returns:\n",
    "    float: The accuracy of the model, expressed as a percentage.\n",
    "    \"\"\"\n",
    "    y_true = y_true.flatten()\n",
    "    total_samples = len(y_true)\n",
    "    correct_predictions = np.sum(y_true == y_pred)\n",
    "    return (correct_predictions / total_samples) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7520175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "accuracy = compute_accuracy(y_test, predictions)\n",
    "print(f\" our model got accuracy score of : {accuracy}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6348d66",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "<h1 style='background:#000000;border:0; color:black;\n",
    "    box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\n",
    "    transform: rotateX(10deg);\n",
    "    '><center style='color: white;'>Sklearn Implementation</center></h1>\n",
    "\n",
    "# Sklearn Implementation\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf17a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "skmodel = KNeighborsClassifier(n_neighbors=7)\n",
    "skmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_predictions = skmodel.predict(X_test)\n",
    "sk_accuracy = compute_accuracy(y_test, sk_predictions)\n",
    "print(f\" sklearn-model got accuracy score of : {sk_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9b6be8",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "<h1 style='background:#000000;border:0; color:black;\n",
    "    box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\n",
    "    transform: rotateX(10deg);\n",
    "    '><center style='color: white;'>Thank You</center></h1>\n",
    "\n",
    "# Thank You\n",
    "\n",
    "\n",
    "**Thank you for taking your time going through this notebook**\n",
    "\n",
    "**If you have any feedback please let me know**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd55f28b",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px; \n",
    "            color:#333333;\n",
    "            margin:10px;\n",
    "            font-size:150%;\n",
    "            display:fill;\n",
    "            border-radius:1px;\n",
    "            border-style:solid;\n",
    "            border-color:#666666;\n",
    "            background-color:#F9F9F9;\n",
    "            overflow:hidden;\">\n",
    "    <center>\n",
    "        <a id='top'></a>\n",
    "        <b>Machine Learning From Scratch Series</b>\n",
    "    </center>\n",
    "    <br>\n",
    "    <ul>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/linear-regression-from-scratch\" style=\"color:#0072B2\">1 - Linear Regression</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/logistic-regression-from-scratch\" style=\"color:#0072B2\">2 -  Logistic Regression</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/kmeans-from-scratch\" style=\"color:#0072B2\">3 - KMeans</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/decision-tree-classifier-from-scratch\" style=\"color:#0072B2\">4 - Decision Trees</a>\n",
    "        </li> \n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/random-forest-classifier-from-scratch\" style=\"color:#0072B2\">5 -  Random Forest</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/knn-from-scratch\" style=\"color:#0072B2\">6 - KNearestNeighbor</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/pca-from-scratch?scriptVersionId=121402593\" style=\"color:#0072B2\">7 - PCA</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/svm-from-scratch\" style=\"color:#0072B2\">8 - SVM</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/naive-bayes-from-scratch\" style=\"color:#0072B2\">9 - Naive Baye</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/optimized-neural-network-from-scratch\" style=\"color:#0072B2\">10 - Optimized Neural Network</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/neural-network-from-scratch\" style=\"color:#0072B2\">11 - Neural Network</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/cnn-from-scratch\" style=\"color:#0072B2\">12 - CNN</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/rnn-from-scratch\" style=\"color:#0072B2\">13 - RNN</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/lstm-from-scratch\" style=\"color:#0072B2\">14 - LSTM</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/gru-from-scratch\" style=\"color:#0072B2\">15 - GRU</a>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
